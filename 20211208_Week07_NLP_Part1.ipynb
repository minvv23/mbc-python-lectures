{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tokenizers # 토큰화(tokenization)\n",
    "import gensim # 임베딩(embedding) : 토큰을 숫자(벡터/좌표)로 변환\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. 데이터 기초 전처리 및 사전 기반 알고리즘의 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "moviedf = pd.read_csv('./data/naver_movie.csv', index_col=0).sample(500)\n",
    "shoppingdf = pd.read_csv('./data/naver_shopping.csv', index_col=0).sample(500)\n",
    "beepdf = pd.read_csv('./data/beep_dataset.csv', index_col=0).sample(500)\n",
    "jobplanetdf = pd.read_csv('./data/jobplanet_review.csv', index_col=0)\n",
    "\n",
    "moviedf.columns = ['text', 'label']\n",
    "shoppingdf.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf =\\\n",
    "pd.concat([moviedf, shoppingdf, beepdf,\n",
    "           jobplanetdf[jobplanetdf['label']==1][['good', 'label']].rename({'good':'text'}, axis=1),\n",
    "           jobplanetdf[jobplanetdf['label']==0][['bad', 'label']].rename({'bad':'text'}, axis=1)],\n",
    "          axis=0, ignore_index=True)\n",
    "textdf['label'] = textdf['label'].replace({0:1, 1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5465084184377588"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words = ['나쁜', '구린', '썩은', '별로', '최악', '끔찍', \n",
    "             '지루', '잠', '환불', '늑장', '늦장', '꼰대', '정치질', '억압'\n",
    "             '하향', '수직']\n",
    "textdf['pred'] = textdf['text'].str.contains('|'.join(bad_words)).astype(int)\n",
    "textdf['correct'] = (textdf['label']==textdf['pred']).astype(int)\n",
    "np.mean(textdf['correct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobiledf = pd.read_csv('./data/mobilecarrier_news.csv', index_col=0)\n",
    "welfaredf = pd.read_csv('./data/welfare_news.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([textdf['text'], \n",
    "                    welfaredf['title'], welfaredf['content'], \n",
    "                    mobiledf['title'].drop_duplicates()], axis=0, ignore_index=True)\n",
    "corpus = corpus.str.replace('\\[(.*?)\\]', '')\n",
    "corpus = corpus.str.split().str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import SentencePieceBPETokenizer\n",
    "bpe_tokenizer = SentencePieceBPETokenizer()\n",
    "bpe_tokenizer.train_from_iterator(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁안녕', '하세요', '저', '는', '방송', '사에서', 'P', 'D', '로', '일을', '하고', '있', '습니다']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_tokenizer.encode('안녕하세요저는방송사에서PD로일을하고있습니다').tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15588/15588 [00:06<00:00, 2595.41it/s]\n"
     ]
    }
   ],
   "source": [
    "token_corpus = []\n",
    "for text in tqdm(corpus) :\n",
    "    token_corpus.append(bpe_tokenizer.encode(text).tokens)\n",
    "    \n",
    "token_corpus = pd.Series(token_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15588/15588 [00:05<00:00, 2606.79it/s]\n"
     ]
    }
   ],
   "source": [
    "token_corpus = pd.Series([bpe_tokenizer.encode(text).tokens for text in tqdm(corpus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [▁가르, 시아, 를, ▁알게, ▁해준, ▁영화, .., 마, 지막, ▁장면, 도,...\n",
       "1        [▁이영, 화를, 보면서, ▁아프, 겠다, 라는, 생각, 이, 들, 엇, 다, ▁ᄏ...\n",
       "2                          [▁이, ▁영화를, ▁보고, ▁암, 이, ▁나, 았다.]\n",
       "3        [▁민, 들, 레, 부모가, ▁전하는, ▁아, 가, 페, 적인, 사랑, ..., 가...\n",
       "4          [▁어린이집, ▁재, 롱, 잔, 치를, ▁만, 원, 주고, ▁보는, ▁기분, 이라면]\n",
       "                               ...                        \n",
       "15583            [▁SKT,, ▁3년, ▁연속, ▁', 최고, ▁이통사, ', ▁영, 예]\n",
       "15584                [▁KT,, ▁AI, ▁코딩, ▁초등, 생, ▁꿈, 나무, ▁시상]\n",
       "15585    [▁', 딸, ▁KT, ▁특별, 채용, ', ▁김성, 태, ▁사퇴, 에, .., 민...\n",
       "15586    [▁SKT,, ▁내일, ▁분할, ▁후, ▁재, 상장, .., 주가, ▁날아, 오를, 까]\n",
       "15587     [▁LG유플러스,, ▁인공지능, ▁관리, ▁'스마트, ▁양, 계, 장, ', ▁만든다]\n",
       "Length: 15588, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. 머신러닝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
