{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tokenizers # 토큰화(tokenization)\n",
    "import gensim # 임베딩(embedding) : 토큰을 숫자(벡터/좌표)로 변환\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. 데이터 기초 전처리 및 사전 기반 알고리즘의 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "moviedf = pd.read_csv('./data/naver_movie.csv', index_col=0).sample(500)\n",
    "shoppingdf = pd.read_csv('./data/naver_shopping.csv', index_col=0).sample(500)\n",
    "beepdf = pd.read_csv('./data/beep_dataset.csv', index_col=0).sample(500)\n",
    "jobplanetdf = pd.read_csv('./data/jobplanet_review.csv', index_col=0)\n",
    "\n",
    "moviedf.columns = ['text', 'label']\n",
    "shoppingdf.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf =\\\n",
    "pd.concat([moviedf, shoppingdf, beepdf,\n",
    "           jobplanetdf[jobplanetdf['label']==1][['good', 'label']].rename({'good':'text'}, axis=1),\n",
    "           jobplanetdf[jobplanetdf['label']==0][['bad', 'label']].rename({'bad':'text'}, axis=1)],\n",
    "          axis=0, ignore_index=True)\n",
    "textdf['label'] = textdf['label'].replace({0:1, 1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5465084184377588"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words = ['나쁜', '구린', '썩은', '별로', '최악', '끔찍', \n",
    "             '지루', '잠', '환불', '늑장', '늦장', '꼰대', '정치질', '억압'\n",
    "             '하향', '수직']\n",
    "textdf['pred'] = textdf['text'].str.contains('|'.join(bad_words)).astype(int)\n",
    "textdf['correct'] = (textdf['label']==textdf['pred']).astype(int)\n",
    "np.mean(textdf['correct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobiledf = pd.read_csv('./data/mobilecarrier_news.csv', index_col=0)\n",
    "welfaredf = pd.read_csv('./data/welfare_news.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([textdf['text'], \n",
    "                    welfaredf['title'], welfaredf['content'], \n",
    "                    mobiledf['title'].drop_duplicates()], axis=0, ignore_index=True)\n",
    "corpus = corpus.str.replace('\\[(.*?)\\]', '')\n",
    "corpus = corpus.str.split().str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import SentencePieceBPETokenizer\n",
    "bpe_tokenizer = SentencePieceBPETokenizer()\n",
    "bpe_tokenizer.train_from_iterator(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁안녕', '하세요', '저', '는', '방송', '사에서', 'P', 'D', '로', '일을', '하고', '있', '습니다']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_tokenizer.encode('안녕하세요저는방송사에서PD로일을하고있습니다').tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15588/15588 [00:11<00:00, 1314.44it/s]\n"
     ]
    }
   ],
   "source": [
    "token_corpus = []\n",
    "for text in tqdm(corpus) :\n",
    "    token_corpus.append(bpe_tokenizer.encode(text).tokens)\n",
    "    \n",
    "token_corpus = pd.Series(token_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15588/15588 [00:11<00:00, 1371.39it/s]\n"
     ]
    }
   ],
   "source": [
    "token_corpus = pd.Series([bpe_tokenizer.encode(text).tokens for text in tqdm(corpus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [▁가르, 시아, 를, ▁알게, ▁해, 준, ▁영화, .., 마, 지막, ▁장면, ...\n",
       "1        [▁이영, 화를, 보면서, ▁아프, 겠다, 라는, 생각, 이, 들, 엇, 다, ▁ᄏ...\n",
       "2                          [▁이, ▁영화를, ▁보고, ▁암, 이, ▁나, 았다.]\n",
       "3        [▁민, 들, 레, 부모가, ▁전하는, ▁아, 가, 페, 적인, 사랑, ..., 가...\n",
       "4          [▁어린이집, ▁재, 롱, 잔, 치를, ▁만, 원, 주고, ▁보는, ▁기분, 이라면]\n",
       "                               ...                        \n",
       "15583            [▁SKT,, ▁3년, ▁연속, ▁', 최고, ▁이통사, ', ▁영, 예]\n",
       "15584                [▁KT,, ▁AI, ▁코딩, ▁초등, 생, ▁꿈, 나무, ▁시상]\n",
       "15585    [▁', 딸, ▁KT, ▁특별, 채용, ', ▁김성, 태, ▁사퇴, 에, .., 민...\n",
       "15586    [▁SKT,, ▁내일, ▁분할, ▁후, ▁재, 상장, .., 주가, ▁날아, 오를, 까]\n",
       "15587     [▁LG유플러스,, ▁인공지능, ▁관리, ▁'스마트, ▁양, 계, 장, ', ▁만든다]\n",
       "Length: 15588, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "w2v_model = Word2Vec(token_corpus, sg=1, epochs=7)\n",
    "ft_model = FastText(token_corpus, sg=1, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1151544"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('연봉', '코로나')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16521913, -0.18701477, -0.39698306,  0.0355202 ,  0.05798006,\n",
       "       -0.13161759, -0.37331873, -0.11356381, -0.10481597, -0.17221938,\n",
       "        0.06244675, -0.2788491 , -0.12742016, -0.0970618 , -0.03446411,\n",
       "        0.08549043,  0.4998588 ,  0.12588818,  0.4782302 , -0.7285214 ,\n",
       "        0.02492709,  0.23192786, -0.75775456,  0.07073252,  0.11411864,\n",
       "        0.25108618,  0.03886351,  0.06889918, -0.69241524, -0.28796047,\n",
       "       -0.06283448,  0.09872311,  0.07186755,  0.12980345,  0.0334126 ,\n",
       "        0.05788888, -0.05179298, -0.00893757,  0.09150636,  0.10221846,\n",
       "        0.03644586,  0.29304215, -0.04010261,  0.08229563,  0.22286223,\n",
       "       -0.38315177, -0.5096461 , -0.09943447,  0.21590006,  0.10774019,\n",
       "        0.03086062, -0.06111997, -0.2096073 ,  0.5522317 , -0.610717  ,\n",
       "       -0.15873753, -0.44212157, -0.17393778, -0.12312325,  0.09924411,\n",
       "        0.00348979, -0.07833613, -0.5191681 ,  0.21401459, -0.03272829,\n",
       "       -0.10123712,  0.09055684,  0.3246691 , -0.04846293,  0.39466476,\n",
       "        0.17503694,  0.37187466,  0.21341492, -0.47026023, -0.1675141 ,\n",
       "       -0.08164171,  0.07269739,  0.47260958,  0.04999329, -0.24215521,\n",
       "       -0.345007  , -0.26402158, -0.13533375, -0.15017955,  0.00811032,\n",
       "       -0.03873438,  0.11037434,  0.13531081,  0.03195185,  0.11376465,\n",
       "        0.17744978,  0.0381957 ,  0.08707616,  0.0039127 ,  0.03801316,\n",
       "       -0.03644625, -0.43593073, -0.02189086,  0.20653789,  0.43966597],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['행복']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. 머신러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = bpe_tokenizer.encode('이 회사는 분위기가 너무 별로다').tokens\n",
    "embedding = np.mean([ft_model.wv[tk] for tk in tokens], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁이', '▁회사는', '▁분위기가', '▁너무', '▁별로', '다']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.03703193e-01,  1.69759005e-01,  1.23933546e-01,  8.58766019e-01,\n",
       "       -2.31962800e-01, -1.75621659e-01, -4.91009712e-01,  4.05360132e-01,\n",
       "       -2.08736733e-02, -7.65724182e-02, -1.16519898e-01,  2.12718487e-01,\n",
       "        5.64340055e-02, -2.61876851e-01, -9.41539407e-02, -4.33692902e-01,\n",
       "        3.42092156e-01,  3.70937586e-02,  3.45549166e-01, -2.68702686e-01,\n",
       "        6.30878136e-02,  1.94062203e-01,  4.24055099e-01,  3.10822845e-01,\n",
       "       -1.54041573e-01,  8.44970942e-02, -2.47456565e-01,  1.96155161e-01,\n",
       "        2.00928092e-01,  9.69892740e-01,  5.60990393e-01, -5.56201935e-01,\n",
       "        1.32961914e-01, -5.05102426e-02,  1.26770914e-01,  3.62415195e-01,\n",
       "       -1.93500459e-01,  3.75687853e-02,  4.75911945e-02, -2.59729683e-01,\n",
       "       -2.50874996e-01,  1.78010389e-01,  2.44793147e-01, -2.59054899e-01,\n",
       "       -4.21470135e-01, -8.07233036e-01,  1.21662267e-01,  3.34195524e-01,\n",
       "       -6.93352103e-01,  5.15397549e-01, -6.21641397e-01, -3.13594043e-02,\n",
       "        1.16999477e-01,  1.07248865e-01, -7.35003293e-01, -2.85483599e-01,\n",
       "       -9.09233391e-02, -9.58568752e-01, -4.39419210e-01,  5.03267050e-01,\n",
       "        1.38108402e-01,  7.33744204e-02,  3.90173584e-01,  7.20725656e-02,\n",
       "       -3.71209681e-02,  6.59988165e-01,  8.83488134e-02,  1.67599022e-01,\n",
       "        3.65319878e-01, -9.82327163e-02,  3.46711636e-01,  1.14223190e-01,\n",
       "        2.14527696e-01, -6.55819476e-01,  5.24034202e-01, -9.46924090e-04,\n",
       "       -8.78206491e-02, -3.10279727e-01,  3.86788249e-01,  3.37876111e-01,\n",
       "       -6.58286959e-02, -2.07943425e-01, -6.67585611e-01, -3.71628791e-01,\n",
       "        1.85938060e-01,  3.38417143e-01, -9.29102302e-03,  4.86379266e-01,\n",
       "        2.24280253e-01,  2.38650471e-01,  3.79084408e-01, -5.12393236e-01,\n",
       "        1.99329108e-01, -1.55729428e-02, -1.83442488e-01,  5.07488728e-01,\n",
       "       -1.09572239e-01,  3.15161526e-01,  1.29366979e-01, -1.40515324e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.wv['▁이']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_embedding(input_sent) :\n",
    "    tokens = bpe_tokenizer.encode(input_sent).tokens\n",
    "    embedding = np.mean([ft_model.wv[tk] for tk in tokens], axis=0)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf['embedding'] = [text_to_embedding(text) for text in textdf['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(np.vstack(textdf['embedding'].values), textdf['label'].values, test_size=.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_clf = svm.SVC()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=0)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7527593818984547, 0.7533039647577092)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀\n",
    "accuracy_score(y_test, lr_clf.predict(X_test)), f1_score(y_test, lr_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7781456953642384, 0.7895287958115182)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 서포트벡터머신\n",
    "accuracy_score(y_test, svm_clf.predict(X_test)), f1_score(y_test, svm_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7770419426048565, 0.7823275862068965)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤포레스트\n",
    "accuracy_score(y_test, rf_clf.predict(X_test)), f1_score(y_test, rf_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_classifier(input_sent) :\n",
    "    embedding = text_to_embedding(input_sent)\n",
    "    output = svm_clf.predict(embedding.reshape(1,-1))[0]\n",
    "    return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier('7ㅐㄴㅏ븐ㅅH77ㅣ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
